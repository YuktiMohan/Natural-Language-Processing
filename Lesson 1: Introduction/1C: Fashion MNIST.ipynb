{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1C: Fashion MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPTUtnEZf1nC/Lz8EzJj5US",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YuktiMohan/Tensorflow-in-Practice/blob/master/Lesson%201%3A%20Introduction/1C%3A%20Fashion%20MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVRTXhLA06Yv",
        "colab_type": "code",
        "outputId": "40f08caf-0f27-4f59-c0c5-43c42ecc2235",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7aF-eeI1Die",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1u5qAFAv1jbq",
        "colab_type": "code",
        "outputId": "9914eadf-cb09-4a2c-d9ee-b302625d3cad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "#Loading the Fashion MNIST dataset and segregating it into training and testing sets\n",
        "\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (testing_images, testing_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nanV_qlB15G8",
        "colab_type": "code",
        "outputId": "24991258-01bf-49cb-db6d-91b5cb2a4a7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        }
      },
      "source": [
        "#To visualise the kind of data we are working with\n",
        "\n",
        "np.set_printoptions(linewidth=200)\n",
        "plt.imshow(training_images[106])\n",
        "print(training_labels[106])\n",
        "print(training_images[106])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "[[  0   0   0   0   0   0   0   0   0 228 215 204 211  63 114 224 200 218 208   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 232 204 203 215 228 221 209 204 205 236   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  34 243 193 196 188 195 192 192 196 198 244  21   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  90 239 193 200 198 201 198 198 199 193 242  74   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 116 228 193 200 197 200 198 197 200 192 236 105   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 146 221 195 199 197 199 197 198 198 193 226 133   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 157 216 196 199 198 201 200 198 199 193 215 162   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 161 216 194 201 201 205 198 203 198 195 212 166   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 151 218 194 196 229 152 127 233 192 194 216 157   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 123 225 194 189 243 122 108 250 188 193 228 127   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0 100 236 191 188 254  56  58 254 188 192 237  81   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  62 242 195 198 255   3  19 254 196 197 241  49   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  36 242 196 199 253   0   0 253 200 197 244  18   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0  13 239 198 203 236   0   0 242 202 201 230   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 231 200 207 210   0   0 238 205 206 200   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 215 203 215 164   0   0 218 207 210 179   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 204 206 218 121   0   0 212 208 212 161   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 200 208 219 129   0   0 206 212 216 145   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 202 207 223 121   0   0 184 215 215 140   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 212 205 222  97   0   0 184 215 214 143   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 225 203 223  80   0   0 176 216 214 156   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 199 204 225  66   0   0 181 216 215 144   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 206 204 222  44   0   0 211 214 219 125   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 208 206 214  23   0   0 217 215 224 122   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 202 209 208   4   0   0 189 219 222 109   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 194 213 192   0   0   0 128 220 216 101   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 198 215 195   0   0   0 106 221 219 137   0   0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0   0 170 216 165   0   0   0  50 211 202  81   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzBiXjNy2lGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Normalising the training and testing images\n",
        "\n",
        "training_images = training_images/255.0\n",
        "testing_images = testing_images/255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knEeDMoK2D8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.Sequential([ \n",
        "                                 keras.layers.Flatten(),\n",
        "                                 keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                 keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOa-HchD6z9J",
        "colab_type": "text"
      },
      "source": [
        "- **Sequential**: That defines a SEQUENCE of layers in the neural network\n",
        "\n",
        "- **Flatten**: It converts a 2D array (here, 28X28) into a 1D array (here, 784X1)\n",
        "\n",
        "- **Dense**: Adds a layer of neurons\n",
        "\n",
        "- Each layer of neurons need an **activation function** to tell them what to do. For example:\n",
        "\n",
        "  1. **Relu** effectively means \"If X>0 return X, else return 0\" -- so what it does it it only passes values 0 or greater to the next layer in the network.\n",
        "\n",
        "  2. **Softmax** takes a set of values, and effectively picks the biggest one, so, for example, if the output of the last layer looks like [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], it saves you from fishing through it looking for the biggest value, and turns it into [0,0,0,0,1,0,0,0,0] -- The goal is to save a lot of coding!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8JEYEMlJ3JDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT9l55zW3aOJ",
        "colab_type": "code",
        "outputId": "83af55ef-9166-48b4-de65-b400ed66f506",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "model.fit(training_images, training_labels, epochs = 10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.4739 - accuracy: 0.8308\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3608 - accuracy: 0.8667\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3236 - accuracy: 0.8795\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2996 - accuracy: 0.8885\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2808 - accuracy: 0.8938\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2653 - accuracy: 0.9004\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2534 - accuracy: 0.9046\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2407 - accuracy: 0.9097\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2313 - accuracy: 0.9118\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2225 - accuracy: 0.9164\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f49d53f1198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee0DGF3E3mJh",
        "colab_type": "code",
        "outputId": "dc4d4f00-5338-43dd-d92f-785c9044b0bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "model.evaluate(testing_images, testing_labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3303 - accuracy: 0.8877\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3303018808364868, 0.8877000212669373]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Cc3buZY6W2-",
        "colab_type": "text"
      },
      "source": [
        "Training accuracy: 91.64%\n",
        "\n",
        "Testing accuracy: 88.77%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY7czv1u7g2a",
        "colab_type": "code",
        "outputId": "447473ac-963f-454a-c70a-f5e895e7ca21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "classifications = model.predict(testing_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(testing_labels[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4.8922351e-09 2.2976145e-10 7.4894180e-10 5.1735339e-12 3.1591434e-11 4.3088212e-04 6.7731300e-08 4.5902366e-03 2.5180366e-10 9.9497885e-01]\n",
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaL6qZiq9VLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.9):\n",
        "      print(\"\\nReached 90% accuracy, hence cancelling training!\")\n",
        "      self.model.stop_training = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCwwtIs6_W5v",
        "colab_type": "text"
      },
      "source": [
        "Callback saves time when we know the requirements of the accuracy/loss as it stops as soon as it reaches the given threshold. Thus it does not train for the entire range of epochs mentioned in the .fit() function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kvap-h1K-JUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callback = myCallback()\n",
        "new_model = keras.models.Sequential([\n",
        "                                    keras.layers.Flatten(),\n",
        "                                    keras.layers.Dense(512, activation = 'relu'),\n",
        "                                    keras.layers.Dense(10, activation = 'softmax')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7i6eCzi-icc",
        "colab_type": "code",
        "outputId": "817a3143-bf7d-4645-ad6b-b4df80231b7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "new_model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "new_model.fit(training_images, training_labels, epochs = 10, callbacks = [callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.4730 - accuracy: 0.8319\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3600 - accuracy: 0.8686\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.3206 - accuracy: 0.8812\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2969 - accuracy: 0.8909\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2780 - accuracy: 0.8973\n",
            "Epoch 6/10\n",
            "1871/1875 [============================>.] - ETA: 0s - loss: 0.2629 - accuracy: 0.9028\n",
            "Reached 90% accuracy, hence cancelling training!\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2630 - accuracy: 0.9027\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f49cc4b1518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    }
  ]
}